<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Visualizing what CONVNETS leran | Computer vision with R and keras</title>
  <meta name="description" content="This book conains tutorials for deep learning applications in computer vision" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Visualizing what CONVNETS leran | Computer vision with R and keras" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book conains tutorials for deep learning applications in computer vision" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Visualizing what CONVNETS leran | Computer vision with R and keras" />
  
  <meta name="twitter:description" content="This book conains tutorials for deep learning applications in computer vision" />
  

<meta name="author" content="Saif Shabou" />


<meta name="date" content="2020-04-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transfer-learning.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Computer vision with Keras and R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Presentation</a></li>
<li class="chapter" data-level="2" data-path="foundamental-of-machine-learning.html"><a href="foundamental-of-machine-learning.html"><i class="fa fa-check"></i><b>2</b> Foundamental of machine learning</a><ul>
<li class="chapter" data-level="2.1" data-path="foundamental-of-machine-learning.html"><a href="foundamental-of-machine-learning.html#types"><i class="fa fa-check"></i><b>2.1</b> Types</a></li>
<li class="chapter" data-level="2.2" data-path="foundamental-of-machine-learning.html"><a href="foundamental-of-machine-learning.html#model-performance-evaluation"><i class="fa fa-check"></i><b>2.2</b> Model performance evaluation</a><ul>
<li class="chapter" data-level="2.2.1" data-path="foundamental-of-machine-learning.html"><a href="foundamental-of-machine-learning.html#training-validation-and-test-sets"><i class="fa fa-check"></i><b>2.2.1</b> Training, validation and test sets</a></li>
<li class="chapter" data-level="2.2.2" data-path="foundamental-of-machine-learning.html"><a href="foundamental-of-machine-learning.html#evaluation-metrics"><i class="fa fa-check"></i><b>2.2.2</b> Evaluation metrics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>3</b> Neural Networks</a><ul>
<li class="chapter" data-level="3.1" data-path="neural-networks.html"><a href="neural-networks.html#structure-of-neural-network"><i class="fa fa-check"></i><b>3.1</b> Structure of neural network</a><ul>
<li class="chapter" data-level="3.1.1" data-path="neural-networks.html"><a href="neural-networks.html#tensors"><i class="fa fa-check"></i><b>3.1.1</b> Tensors</a></li>
<li class="chapter" data-level="3.1.2" data-path="neural-networks.html"><a href="neural-networks.html#layers"><i class="fa fa-check"></i><b>3.1.2</b> Layers</a></li>
<li class="chapter" data-level="3.1.3" data-path="neural-networks.html"><a href="neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>3.1.3</b> Activation functions</a></li>
<li class="chapter" data-level="3.1.4" data-path="neural-networks.html"><a href="neural-networks.html#loss-functions-and-optimizers"><i class="fa fa-check"></i><b>3.1.4</b> Loss functions and optimizers</a></li>
<li class="chapter" data-level="3.1.5" data-path="neural-networks.html"><a href="neural-networks.html#building-a-neural-network-from-scratch"><i class="fa fa-check"></i><b>3.1.5</b> Building a Neural Network from scratch</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="neural-networks.html"><a href="neural-networks.html#introduction-to-keras"><i class="fa fa-check"></i><b>3.2</b> Introduction to Keras</a><ul>
<li class="chapter" data-level="3.2.1" data-path="neural-networks.html"><a href="neural-networks.html#installing-keras"><i class="fa fa-check"></i><b>3.2.1</b> Installing keras</a></li>
<li class="chapter" data-level="3.2.2" data-path="neural-networks.html"><a href="neural-networks.html#building-model-with-keras"><i class="fa fa-check"></i><b>3.2.2</b> building model with keras</a></li>
<li class="chapter" data-level="3.2.3" data-path="neural-networks.html"><a href="neural-networks.html#the-kears-functional-api"><i class="fa fa-check"></i><b>3.2.3</b> The Kears Functional API</a></li>
<li class="chapter" data-level="3.2.4" data-path="neural-networks.html"><a href="neural-networks.html#models-as-directed-acyclic-graphs-of-layers"><i class="fa fa-check"></i><b>3.2.4</b> Models as Directed acyclic graphs of layers</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="neural-networks.html"><a href="neural-networks.html#monitoring-deep-learning-models"><i class="fa fa-check"></i><b>3.3</b> Monitoring deep learning models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="neural-networks.html"><a href="neural-networks.html#using-callbacks"><i class="fa fa-check"></i><b>3.3.1</b> Using callbacks</a></li>
<li class="chapter" data-level="3.3.2" data-path="neural-networks.html"><a href="neural-networks.html#tensorboard"><i class="fa fa-check"></i><b>3.3.2</b> TensorBoard</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="neural-networks.html"><a href="neural-networks.html#batch-normalization"><i class="fa fa-check"></i><b>3.4</b> Batch normalization</a></li>
<li class="chapter" data-level="3.5" data-path="neural-networks.html"><a href="neural-networks.html#overfitting-handling"><i class="fa fa-check"></i><b>3.5</b> Overfitting handling</a><ul>
<li class="chapter" data-level="3.5.1" data-path="neural-networks.html"><a href="neural-networks.html#reducing-the-networks-size"><i class="fa fa-check"></i><b>3.5.1</b> Reducing the networkâ€™s size</a></li>
<li class="chapter" data-level="3.5.2" data-path="neural-networks.html"><a href="neural-networks.html#adding-weight-regularization"><i class="fa fa-check"></i><b>3.5.2</b> Adding weight regularization</a></li>
<li class="chapter" data-level="3.5.3" data-path="neural-networks.html"><a href="neural-networks.html#adding-dropout"><i class="fa fa-check"></i><b>3.5.3</b> Adding dropout</a></li>
<li class="chapter" data-level="3.5.4" data-path="neural-networks.html"><a href="neural-networks.html#data-augmentation"><i class="fa fa-check"></i><b>3.5.4</b> Data augmentation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="neural-networks.html"><a href="neural-networks.html#hyperparameters-optimization"><i class="fa fa-check"></i><b>3.6</b> Hyperparameters optimization</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html"><i class="fa fa-check"></i><b>4</b> Deep learning for computer vision</a><ul>
<li class="chapter" data-level="4.1" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#image-classification-with-keras"><i class="fa fa-check"></i><b>4.1</b> Image classification with Keras</a><ul>
<li class="chapter" data-level="4.1.1" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#download-and-prepare-the-data"><i class="fa fa-check"></i><b>4.1.1</b> download and prepare the data</a></li>
<li class="chapter" data-level="4.1.2" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#build-the-model"><i class="fa fa-check"></i><b>4.1.2</b> Build the model</a></li>
<li class="chapter" data-level="4.1.3" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#compile-the-model"><i class="fa fa-check"></i><b>4.1.3</b> Compile the model</a></li>
<li class="chapter" data-level="4.1.4" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#fit-the-model"><i class="fa fa-check"></i><b>4.1.4</b> Fit the model</a></li>
<li class="chapter" data-level="4.1.5" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#make-predictions"><i class="fa fa-check"></i><b>4.1.5</b> Make predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#evaluate-the-model"><i class="fa fa-check"></i><b>4.1.6</b> Evaluate the model</a></li>
<li class="chapter" data-level="4.1.7" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#save-the-model"><i class="fa fa-check"></i><b>4.1.7</b> Save the model</a></li>
<li class="chapter" data-level="4.1.8" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#reload-the-model"><i class="fa fa-check"></i><b>4.1.8</b> reload the model</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#introduction-to-convolution-neural-networks"><i class="fa fa-check"></i><b>4.2</b> Introduction to Convolution Neural Networks</a><ul>
<li class="chapter" data-level="4.2.1" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#example"><i class="fa fa-check"></i><b>4.2.1</b> Example</a></li>
<li class="chapter" data-level="4.2.2" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#the-convolution-operation"><i class="fa fa-check"></i><b>4.2.2</b> The convolution operation</a></li>
<li class="chapter" data-level="4.2.3" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#the-max-pooling-operation"><i class="fa fa-check"></i><b>4.2.3</b> The max-pooling operation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#architectures-of-cnn"><i class="fa fa-check"></i><b>4.3</b> Architectures of CNN</a></li>
<li class="chapter" data-level="4.4" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#classifcation-examples"><i class="fa fa-check"></i><b>4.4</b> Classifcation examples</a><ul>
<li class="chapter" data-level="4.4.1" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#dataset-dog-vs-cats"><i class="fa fa-check"></i><b>4.4.1</b> Dataset: Dog VS Cats</a></li>
<li class="chapter" data-level="4.4.2" data-path="deep-learning-for-computer-vision.html"><a href="deep-learning-for-computer-vision.html#dataset-cifar10"><i class="fa fa-check"></i><b>4.4.2</b> Dataset: CIFAR10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="transfer-learning.html"><a href="transfer-learning.html"><i class="fa fa-check"></i><b>5</b> Transfer learning</a><ul>
<li class="chapter" data-level="5.1" data-path="transfer-learning.html"><a href="transfer-learning.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="transfer-learning.html"><a href="transfer-learning.html#what-is-transfer-learning"><i class="fa fa-check"></i><b>5.1.1</b> What is Transfer Learning</a></li>
<li class="chapter" data-level="5.1.2" data-path="transfer-learning.html"><a href="transfer-learning.html#what-is-tensforflow-hub"><i class="fa fa-check"></i><b>5.1.2</b> What is TensforFlow Hub</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="transfer-learning.html"><a href="transfer-learning.html#transfer-learning-with-tensforflow-hub"><i class="fa fa-check"></i><b>5.2</b> Transfer learning with TensforFlow Hub</a><ul>
<li class="chapter" data-level="5.2.1" data-path="transfer-learning.html"><a href="transfer-learning.html#imagenet-classifier"><i class="fa fa-check"></i><b>5.2.1</b> ImageNet classifier</a></li>
<li class="chapter" data-level="5.2.2" data-path="transfer-learning.html"><a href="transfer-learning.html#transfer-learning-1"><i class="fa fa-check"></i><b>5.2.2</b> Transfer learning</a></li>
<li class="chapter" data-level="5.2.3" data-path="transfer-learning.html"><a href="transfer-learning.html#run-the-classifier-on-a-batch-of-images"><i class="fa fa-check"></i><b>5.2.3</b> Run the classifier on a batch of images</a></li>
<li class="chapter" data-level="5.2.4" data-path="transfer-learning.html"><a href="transfer-learning.html#download-a-headless-model"><i class="fa fa-check"></i><b>5.2.4</b> Download a headless model</a></li>
<li class="chapter" data-level="5.2.5" data-path="transfer-learning.html"><a href="transfer-learning.html#attach-a-classification-head"><i class="fa fa-check"></i><b>5.2.5</b> Attach a classification head</a></li>
<li class="chapter" data-level="5.2.6" data-path="transfer-learning.html"><a href="transfer-learning.html#train-the-model"><i class="fa fa-check"></i><b>5.2.6</b> Train the model</a></li>
<li class="chapter" data-level="5.2.7" data-path="transfer-learning.html"><a href="transfer-learning.html#export-the-model"><i class="fa fa-check"></i><b>5.2.7</b> Export the model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="transfer-learning.html"><a href="transfer-learning.html#transfer-learning-using-a-pretrained-convnet"><i class="fa fa-check"></i><b>5.3</b> Transfer learning using a pretrained CONVNET</a><ul>
<li class="chapter" data-level="5.3.1" data-path="transfer-learning.html"><a href="transfer-learning.html#feature-extraction"><i class="fa fa-check"></i><b>5.3.1</b> feature extraction</a></li>
<li class="chapter" data-level="5.3.2" data-path="transfer-learning.html"><a href="transfer-learning.html#fine-tuning"><i class="fa fa-check"></i><b>5.3.2</b> Fine-tuning</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="visualizing-what-convnets-leran.html"><a href="visualizing-what-convnets-leran.html"><i class="fa fa-check"></i><b>6</b> Visualizing what CONVNETS leran</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Computer vision with R and keras</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="visualizing-what-convnets-leran" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Visualizing what CONVNETS leran</h1>
<p>Keras offers the possibility to visualize the learning process. This may help to understand better how the model works. We can try to visualize different steps in learning rocess: the activation process, the convnet filters or the clall of activation. We wil give an example of visualizing the intermediate activation here. for more tools, you can look at the keras book: <a href="https://www.manning.com/books/deep-learning-with-r" class="uri">https://www.manning.com/books/deep-learning-with-r</a></p>
<p><strong>Visualizing intermediate activations</strong></p>
<p>It consists of visualizing the feature maps that are output by the different convolution and pooling operations in the network. We can visualize feature maps in 3 domensions: width, height, and depth (channel). Each channel encodes relatively independent features that we can plot them in independent plots.</p>
<ul>
<li>loading cat vs dog model</li>
</ul>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb196-1" title="1"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb196-2" title="2">model =<span class="st"> </span><span class="kw">load_model_hdf5</span>(<span class="st">&quot;D:/image/DeepLearning-ComputerVision/models/cats_and_dogs_small_2.h5&quot;</span>)</a>
<a class="sourceLine" id="cb196-3" title="3">model</a></code></pre></div>
<pre><code>## Model
## Model: &quot;sequential_3&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## conv2d_3 (Conv2D)                   (None, 148, 148, 32)            896         
## ________________________________________________________________________________
## max_pooling2d_2 (MaxPooling2D)      (None, 74, 74, 32)              0           
## ________________________________________________________________________________
## conv2d_4 (Conv2D)                   (None, 72, 72, 64)              18496       
## ________________________________________________________________________________
## max_pooling2d_3 (MaxPooling2D)      (None, 36, 36, 64)              0           
## ________________________________________________________________________________
## conv2d_5 (Conv2D)                   (None, 34, 34, 128)             73856       
## ________________________________________________________________________________
## max_pooling2d_4 (MaxPooling2D)      (None, 17, 17, 128)             0           
## ________________________________________________________________________________
## conv2d_6 (Conv2D)                   (None, 15, 15, 128)             147584      
## ________________________________________________________________________________
## max_pooling2d_5 (MaxPooling2D)      (None, 7, 7, 128)               0           
## ________________________________________________________________________________
## flatten_2 (Flatten)                 (None, 6272)                    0           
## ________________________________________________________________________________
## dense_10 (Dense)                    (None, 512)                     3211776     
## ________________________________________________________________________________
## dense_11 (Dense)                    (None, 1)                       513         
## ================================================================================
## Total params: 3,453,121
## Trainable params: 3,453,121
## Non-trainable params: 0
## ________________________________________________________________________________</code></pre>
<ul>
<li>Specify an input image from the cat dataset</li>
</ul>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" title="1">img_path =<span class="st"> &quot;D:/image/DeepLearning-ComputerVision/data/cats_and_dogs_small/train/cats/cat.1.jpg&quot;</span></a>
<a class="sourceLine" id="cb198-2" title="2">img =<span class="st"> </span><span class="kw">image_load</span>(img_path, <span class="dt">target_size =</span> <span class="kw">c</span>(<span class="dv">150</span>,<span class="dv">150</span>))</a>
<a class="sourceLine" id="cb198-3" title="3">img_tensor =<span class="st"> </span><span class="kw">image_to_array</span>(img)</a>
<a class="sourceLine" id="cb198-4" title="4">img_tensor =<span class="st"> </span><span class="kw">array_reshape</span>(img_tensor, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">150</span>, <span class="dv">150</span>, <span class="dv">3</span>))</a>
<a class="sourceLine" id="cb198-5" title="5">img_tensor =<span class="st"> </span>img_tensor<span class="op">/</span><span class="dv">255</span></a>
<a class="sourceLine" id="cb198-6" title="6"><span class="kw">dim</span>(img_tensor)</a></code></pre></div>
<pre><code>## [1]   1 150 150   3</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb200-1" title="1"><span class="kw">plot</span>(<span class="kw">as.raster</span>(img_tensor[<span class="dv">1</span>,,,]))</a></code></pre></div>
<p><img src="DeepLearning-ComputerVision_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<ul>
<li>Extraction of feature maps: We create a Keras model that takes batches of images as input, and ouputs the activations of all convolution and pooling layers.</li>
</ul>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" title="1">layer_outputs =<span class="st"> </span><span class="kw">lapply</span>(model<span class="op">$</span>layers[<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>], <span class="cf">function</span>(layer) layer<span class="op">$</span>output)</a>
<a class="sourceLine" id="cb201-2" title="2">activation_model =<span class="st"> </span><span class="kw">keras_model</span>(<span class="dt">inputs =</span> model<span class="op">$</span>input,</a>
<a class="sourceLine" id="cb201-3" title="3">                               <span class="dt">outputs =</span> layer_outputs)</a></code></pre></div>
<ul>
<li>Application to one image: We give one image as input to our model. It will return the values of the layer activations in the original model. Our model has one input (the image) and 8 outputs (one output by layer activation).</li>
</ul>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" title="1">activations =<span class="st"> </span>activation_model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict</span>(img_tensor) </a>
<a class="sourceLine" id="cb202-2" title="2"><span class="co"># exaple of the first activation</span></a>
<a class="sourceLine" id="cb202-3" title="3">first_layer_activation =<span class="st"> </span>activations[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb202-4" title="4">last_layer_activation =<span class="st"> </span>activations[[<span class="dv">8</span>]]</a>
<a class="sourceLine" id="cb202-5" title="5"><span class="kw">dim</span>(first_layer_activation)</a></code></pre></div>
<pre><code>## [1]   1 148 148  32</code></pre>
<ul>
<li>Visualization</li>
</ul>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb204-1" title="1"><span class="co"># defining a function to plot a channel</span></a>
<a class="sourceLine" id="cb204-2" title="2">plot_channel =<span class="st"> </span><span class="cf">function</span>(channel) {</a>
<a class="sourceLine" id="cb204-3" title="3">  rotate =<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">t</span>(<span class="kw">apply</span>(x, <span class="dv">2</span>, rev))</a>
<a class="sourceLine" id="cb204-4" title="4">  <span class="kw">image</span>(<span class="kw">rotate</span>(channel), <span class="dt">axes =</span> <span class="ot">FALSE</span>, <span class="dt">asp =</span> <span class="dv">1</span>,</a>
<a class="sourceLine" id="cb204-5" title="5">        <span class="dt">col =</span> <span class="kw">terrain.colors</span>(<span class="dv">12</span>))</a>
<a class="sourceLine" id="cb204-6" title="6">}</a>
<a class="sourceLine" id="cb204-7" title="7"><span class="co">#  plot channel 1</span></a>
<a class="sourceLine" id="cb204-8" title="8"><span class="kw">plot_channel</span>(first_layer_activation[<span class="dv">1</span>,,,<span class="dv">1</span>])</a></code></pre></div>
<p><img src="DeepLearning-ComputerVision_files/figure-html/unnamed-chunk-101-1.png" width="672" /></p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" title="1"><span class="co">#  plot channel 7</span></a>
<a class="sourceLine" id="cb205-2" title="2"><span class="kw">plot_channel</span>(last_layer_activation[<span class="dv">1</span>,,,<span class="dv">1</span>])</a></code></pre></div>
<p><img src="DeepLearning-ComputerVision_files/figure-html/unnamed-chunk-101-2.png" width="672" /></p>
<p>We see that the first layer perform as edge detectors and that as we go higher higher the activations become inceasingly abstract.</p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="transfer-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DeepLearning-ComputerVision.pdf", "DeepLearning-ComputerVision.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
